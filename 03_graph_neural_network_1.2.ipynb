{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ed315cb-3e95-4b9e-bc33-f757bb2c726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from rdkit import Chem\n",
    "\n",
    "# Load the original data with SMILES\n",
    "url = 'https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Function to convert molecules to graph data objects\n",
    "def mol_to_graph(smiles, y=None):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    # Get atom features\n",
    "    num_atoms = mol.GetNumAtoms()\n",
    "    \n",
    "    # Simple atom features: atomic number and aromatic flag\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features.append([\n",
    "            atom.GetAtomicNum(),\n",
    "            1 if atom.GetIsAromatic() else 0,\n",
    "            atom.GetTotalDegree(),\n",
    "            atom.GetFormalCharge(),\n",
    "            atom.GetTotalNumHs()\n",
    "        ])\n",
    "    \n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    \n",
    "    # Get edge indices (bonds)\n",
    "    edge_indices = []\n",
    "    edge_features = []\n",
    "    \n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        bond_type = bond.GetBondTypeAsDouble()\n",
    "        \n",
    "        # Add both directions for undirected graph\n",
    "        edge_indices.append([i, j])\n",
    "        edge_indices.append([j, i])\n",
    "\n",
    "        #Add same bond features for both directions\n",
    "        edge_features.append([bond_type])\n",
    "        edge_features.append([bond_type])\n",
    "        \n",
    "    if len(edge_indices) == 0:  # Handle molecules with no bonds\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.zeros((0,1), dtype=torch.float)\n",
    "    else:\n",
    "        edge_index = torch.tensor(edge_indices, dtype=torch.long).t()\n",
    "        edge_attr = torch.tensor(edge_features,dtype=torch.float)\n",
    "    \n",
    "    # Create data object\n",
    "    data = Data(x=x, edge_index=edge_index,edge_attr=edge_attr)\n",
    "    \n",
    "    if y is not None:\n",
    "        data.y = torch.tensor([y], dtype=torch.float)\n",
    "        \n",
    "    return data\n",
    "\n",
    "# Convert SMILES to graph objects with solubility values\n",
    "graph_data_list = []\n",
    "target_column = 'measured log solubility in mols per litre'\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    smiles = row['smiles']\n",
    "    y = row[target_column]\n",
    "    data = mol_to_graph(smiles, y)\n",
    "    if data is not None:\n",
    "        graph_data_list.append(data)\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(graph_data_list, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74648f14-053d-400e-8154-53191b23fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, GATConv, global_mean_pool, global_add_pool\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class enhancedGNN(torch.nn.Module):\n",
    "    def __init__(self,num_features=5,hidden_dim=64):\n",
    "        super(enhancedGNN, self).__init__()\n",
    "\n",
    "        #first GC layer\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        #second GC Layer\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        #third GC Layer\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        #Fully connected layers\n",
    "        self.fc1 = nn.Linear(hidden_dim, 32)\n",
    "        self.fc2 = nn.Linear(32,1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # First conv block\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "\n",
    "        # Second conv block\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        \n",
    "        # Third conv block\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Global pooling to get graph-level representation\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.dropout(x,p=0.2, training=self.training)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0d42d15-2c21-432f-802f-dcb9f645a36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ria/Documents/YRP_iiit/Mac_Lea/molecular_property_prediction/venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ria/Documents/YRP_iiit/Mac_Lea/molecular_property_prediction/venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Loss: 1.7918, Test Loss: 8.0245\n",
      "Epoch: 020, Train Loss: 1.6039, Test Loss: 7.7406\n",
      "Early stopping triggered after epoch 22\n",
      "Best model was at epoch 2 with test loss 6.7360\n",
      "Test MSE: 2.8759\n",
      "Test RMSE: 1.6959\n",
      "Test R²: 0.3916\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = enhancedGNN(num_features=5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor = 0.5, patience=10, min_lr=1e-6)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data.y)\n",
    "        loss.backward()\n",
    "        #Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "def train_with_early_stopping(patience=20):\n",
    "    best_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "\n",
    "    for epoch in range(200): \n",
    "        train_loss = train()\n",
    "        test_loss, _, _ = test(test_loader)\n",
    "\n",
    "        #Learning rate scheduling\n",
    "        scheduler.step(test_loss)\n",
    "    \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch: {epoch+1:03d}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "        #check if this is the best\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            best_epoch = epoch\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            epoch_no_improve = 0\n",
    "        else:\n",
    "            epoch_no_improve +=1\n",
    "\n",
    "        #early stopping check\n",
    "        if epoch_no_improve >= patience:\n",
    "            print(f'Early stopping triggered after epoch {epoch+1}')\n",
    "            print(f'Best model was at epoch {best_epoch+1} with test loss {best_loss:.4f}')\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return best_epoch, best_loss\n",
    "\n",
    "import copy\n",
    "best_epoch, best_loss = train_with_early_stopping(patience=20)\n",
    "\n",
    "# Final evaluation\n",
    "_, test_pred, test_actual = test(test_loader)\n",
    "mse = mean_squared_error(test_actual, test_pred)\n",
    "r2 = r2_score(test_actual, test_pred)\n",
    "\n",
    "print(f'Test MSE: {mse:.4f}')\n",
    "print(f'Test RMSE: {np.sqrt(mse):.4f}')\n",
    "print(f'Test R²: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82171a17-aaaa-4f9b-af48-5833c1cd16c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Molecular Prediction)",
   "language": "python",
   "name": "molecular_prediction_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
